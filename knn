import torch
import numpy as np
from PIL import Image

im = Image.open('rose.jpeg')
im_small = im.resize((128, 128))
im_small

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import random_split, DataLoader
from torch.utils.tensorboard import SummaryWriter
import os

from torchvision.utils import make_grid

# Helper to log a batch of 32 images from a DataLoader
def log_images_from_loader(name, loader):
    # Get a batch of 32 images and labels
    images, labels = next(iter(loader))
    img_grid = make_grid(images[:32], nrow=8, normalize=True)
    writer.add_image(f'{name}/images', img_grid)

# Log sample images from each dataset
log_images_from_loader("Train", train_loader)
log_images_from_loader("Validation", val_loader)
log_images_from_loader("Test", test_loader)


# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
input_size = 28 * 28
num_classes = 10
batch_size = 64
learning_rate = 0.01
num_epochs = 5
val_split = 0.1

# Setup TensorBoard writer
log_dir = "runs/mnist_linear"
os.makedirs(log_dir, exist_ok=True)
writer = SummaryWriter(log_dir)

# Data transforms
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# Load data
full_train = datasets.MNIST(root='data', train=True, transform=transform, download=True)
test_data = datasets.MNIST(root='data', train=False, transform=transform)

val_size = int(len(full_train) * val_split)
train_size = len(full_train) - val_size
train_data, val_data = random_split(full_train, [train_size, val_size])

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

# Simple linear model
class LinearNN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(LinearNN, self).__init__()
        self.fc = nn.Linear(input_size, num_classes)

    def forward(self, x):
        x = x.view(-1, input_size)
        return self.fc(x)

model = LinearNN(input_size, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate)

# Accuracy function
def get_accuracy(loader, model):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (preds == labels).sum().item()
    return 100 * correct / total

# Training loop with logging
for epoch in range(num_epochs):
    model.train()
    running_loss = 0
    correct, total = 0, 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_loss = running_loss / len(train_loader)
    train_acc = 100 * correct / total

    # Validation loss and accuracy
    model.eval()
    val_loss = 0
    val_correct, val_total = 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            val_correct += (preds == labels).sum().item()
            val_total += labels.size(0)

    val_loss /= len(val_loader)
    val_acc = 100 * val_correct / val_total

    # Log to TensorBoard
    writer.add_scalar('Loss/Train', train_loss, epoch)
    writer.add_scalar('Loss/Validation', val_loss, epoch)
    writer.add_scalar('Accuracy/Train', train_acc, epoch)
    writer.add_scalar('Accuracy/Validation', val_acc, epoch)

    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% "
          f"| Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

# Final test accuracy
test_acc = get_accuracy(test_loader, model)
print(f"Test Accuracy: {test_acc:.2f}%")
writer.add_scalar('Accuracy/Test', test_acc)

writer.close()



class FourierFeatures(torch.nn.Module):
    def __init__(self, num_features=256, scale=10.0):
        super().__init__()
        self.B = torch.randn((2, num_features)) * scale  # 2 input dims (x, y)

    def forward(self, x):
        x_proj = 2 * torch.pi * x @ self.B.to(x.device)
        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)

class Rose(torch.nn.Module):
    def __init__(self) -> None:
        super().__init__()
        # self.enc = torch.nn.Identity()
        self.enc = torch.nn.Sequential(
            torch.nn.Linear(2, 64),
            torch.nn.ReLU(),
            torch.nn.Linear(64, 512),
        )
        # self.enc = FourierFeatures(256)
        self.net = torch.nn.Sequential(
            # torch.nn.Linear(2, 256),
            torch.nn.Linear(512, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, 64),
            torch.nn.ReLU(),
            torch.nn.Linear(64, 3),
        )

    def forward(self, x):
        return self.net(self.enc(x))

rose_tensor = torch.as_tensor(np.array(im_small), dtype=torch.float32) / 255. - 0.5
position = torch.stack(torch.meshgrid(torch.linspace(-1, 1, 128), torch.linspace(-1, 1, 128)), dim=-1)

net = Rose()

# rose_tensor = rose_tensor.cuda()
# position = position.cuda()
# net = net.cuda()

optim = torch.optim.Adam(net.parameters(), lr=1e-3)
for it in range(1000):
    optim.zero_grad()
    loss = abs(net(position) - rose_tensor).mean()
    if it % 100 == 0:
        print("Epoch ", it, " ,", float(loss))
    loss.backward()
    optim.step()


i=128
position = torch.stack(torch.meshgrid(torch.linspace(-1, 1, i), torch.linspace(-1, 1, i)), dim=-1)

# position = torch.stack(torch.meshgrid(torch.linspace(-1, 1, 256), torch.linspace(-1, 1, 256)), dim=-1)

Image.fromarray(((net(position) + 0.5).clamp(0, 1) * 255).cpu().to(torch.uint8).numpy())


import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(-1, 1, 100)
# x= torch.randn(10)
# for w in [1, 5, 20]:
for w in [10]:
    plt.plot(x, np.sin(w * x), label=f'sin({w}x)')

plt.legend()
plt.title("Wave patterns created by sin(w * x)")
plt.grid(True)
plt.show()



import matplotlib.pyplot as plt
import torch

def plot_feature_maps(feature_map, layer_name, num_cols=8):
    """
    Plots all feature maps (channels) of a given layer.

    Args:
        feature_map (torch.Tensor): Feature maps from a given layer (C, H, W) where
                                    C is the number of channels.
        layer_name (str): Name of the layer.
        num_cols (int): Number of columns in the grid plot.
    """
    # Ensure feature_map is a tensor and move to CPU if necessary
    feature_map = feature_map.cpu().detach().numpy()  # Convert to NumPy after ensuring it's on CPU

    # Extract dimensions: C = Channels, H = Height, W = Width
    C, H, W = feature_map.shape  # Explicitly showing that index 0 is the channel

    print(f"Feature Map Shape: {C} channels, {H} height, {W} width")  # Debug info

    # Compute number of rows based on the number of channels
    num_rows = (C + num_cols - 1) // num_cols  # Ensure all feature maps are displayed

    # Create subplots
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 2))
    fig.suptitle(f"Feature Maps of {layer_name}", fontsize=14)

    # Flatten axes array if num_rows == 1
    if num_rows == 1:
        axes = [axes]

    # Plot each feature map (channel)
    for i in range(C):
        row, col = divmod(i, num_cols)
        ax = axes[row][col] if num_rows > 1 else axes[col]
        # ax.imshow(feature_map[i], cmap="gray")  # Correctly plotting each channel
        ax.imshow(feature_map[i])  # Correctly plotting each channel

        ax.axis("off")
        ax.set_title(f"Ch {i}")  # Channel index explicitly shown

    # Hide any unused subplots
    for j in range(i + 1, num_cols * num_rows):
        row, col = divmod(j, num_cols)
        axes[row][col].axis("off")

    plt.show()

# Example usage



import torch
import torchvision
from torchvision.transforms import Compose, Resize, ToTensor
from PIL import Image
import matplotlib.pyplot as plt

# **Step 1: Dataset Preparation**
# Define the image size and transformations
size = (128, 128)
transform = Compose([
    Resize(size),
    ToTensor()
])

import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

# Load an image from file
image_path = "your_image.jpg"  # Replace with your image path
image = Image.open(image_path).convert("RGB")  # Ensure it's RGB (3 channels)

# Define transformations
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize to 64x64
    transforms.ToTensor(),  # Convert to tensor (C, H, W)
])

# Apply transformations
x = transform(image)  # Shape: (3, 64, 64)

# Add batch dimension to match (1, 3, 64, 64)
x = x.unsqueeze(0)  # Shape: (1, 3, 64, 64)

# Display the loaded image
plt.imshow(image)
plt.title("Loaded Image")
plt.axis("off")
plt.show()


import torch
import torch.nn as nn

class ConvNet(nn.Module):
    class Block(nn.Module):
        def __init__(self, in_channels, out_channels, kernel_size, stride):
            super().__init__()
            padding = kernel_size // 2
            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
            self.relu = nn.ReLU()

        def forward(self, x):
            return self.relu(self.conv(x))

    def __init__(self, channels_1_0=64, n_blocks=4):
        super().__init__()

        cnn_layers = [
            nn.Conv2d(3, channels_1_0, kernel_size=11, stride=2, padding=5),
            nn.ReLU(),
        ]

        layers = [64, 128, 256, 512]  # Example channel sizes for the blocks
        c1 = channels_1_0

        for c2 in layers:
            cnn_layers.append(self.Block(c1, c2, kernel_size=3, stride=1))
            c1 = c2  # Current output channels become next input channels

        cnn_layers.append(nn.Conv2d(c1, 1, kernel_size=1))
        # Optional: Apply global average pooling to reduce spatial size to 1x1
        # cnn_layers.append(nn.AdaptiveAvgPool2d(1))

        self.network = nn.Sequential(*cnn_layers)

    def forward(self, x):
        return self.network(x)





from torchvision import datasets
from torchvision.transforms import ToTensor

train_data = datasets.FashionMNIST(root="data", train=True, download=True, transform=ToTensor())
test_data = datasets.FashionMNIST(root="data", train=False, download=True, transform=ToTensor())

# Extract train and test labels
train_data_labels = train_data.targets
test_data_labels = test_data.targets


import matplotlib.pyplot as plt
figure = plt.figure(figsize=(8, 8))
figure.add_subplot(1,6,1)

i=1000
img, label = train_data[i]
# print("img squeeze ", img.squeeze().shape)
# print("img without squeeze ", img.shape)

plt.title(label)
# plt.axis("off")
plt.imshow(img.squeeze(), cmap="gray")

# figure.add_subplot(1,6,6)
# img, label = train_data[200]

# plt.title(label)
# plt.imshow(img.squeeze(), cmap="gray")


# plt.show()


# Model definition #

model = torch.nn.Linear(28*28,10)
# model.parameters() #returns the weights and bias
loss = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), 0.1)

# Training Step #

# print("Weights = ", model.weight.shape)
# print("Bias = ", model.bias)

wt_mean_square = model.weight.pow(2).mean()
print("Weights MSE before training", wt_mean_square.item())

bias_mean_square = model.bias.pow(2).mean()
print("Bias MSE before training", bias_mean_square.item())

metrics = {"train_acc": [], "val_acc": []}

for i in range(60000):
    pred = model(train_data[i][0].squeeze().flatten())
    # print("Pred = ", pred)
    # print("Label = ", train_data[i][1])
    # print("Step ", i)

    optimizer.zero_grad()
    loss_val = loss(pred,torch.tensor(train_data[i][1]))
    loss_val.backward()
    # print("Weights Grad = ", model.weight.grad.pow(2).mean().item())
    optimizer.step()
    train_acc = (torch.argmax(pred) == train_data[i][1]).sum()
    print("Pred = ", torch.argmax(pred), " Label = ", train_data[i][1], " Match = ", torch.argmax(pred) == train_data[i][1])
    metrics["train_acc"].append(train_acc.item())


# print("Weights = ", model.weight)
# print("Bias = ", model.bias)
print("metrics[train_acc] = ", metrics["train_acc"])
print("Accuracy % = ", sum(metrics["train_acc"]) / len(metrics["train_acc"]) * 100)


wt_mean_square = model.weight.pow(2).mean()
print("Weights MSE after training", wt_mean_square.item())

bias_mean_square = model.bias.pow(2).mean()
print("Bias MSE after training", bias_mean_square.item())



# Validation #
metrics = {"val_acc": [], "preds": []}

labels_map = {
    0: "T-Shirt",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle Boot",
}

for i in range(10000):
    pred = model(train_data[i][0].squeeze().flatten())
    # print(torch.argmax(pred)==train_data[i][1])
    metrics["preds"].append(labels_map[torch.argmax(pred).item()])
    acc = (torch.argmax(pred)==train_data[i][1]).sum()
    metrics["val_acc"].append(acc.item())

print("Accuracy % =", sum(metrics["val_acc"])/ len(metrics["val_acc"]) * 100)
print("Pred Accuracy =",metrics["val_acc"] )
print("Predictions =",metrics["preds"] )

import matplotlib.pyplot as plt
figure = plt.figure(figsize=(8, 8))
figure.add_subplot(1,6,1)

i=2
img, label = test_data[i]
# print("img squeeze ", img.squeeze().shape)
# print("img without squeeze ", img.shape)

plt.title(label)
# plt.axis("off")
plt.imshow(img.squeeze(), cmap="gray")

//
# Load the Flowers102 dataset
train_dataset = torchvision.datasets.Flowers102(
    "./flowers", "train", transform=transform, download=True
)
test_dataset = torchvision.datasets.Flowers102(
    "./flowers", "train", transform=transform, download=True
)

import torch
import torch.nn as nn

class MyModel(torch.nn.Module):
    def __init__(self, layer_size=[512, 512, 512]) -> None:
        super().__init__()
        layers = []
        layers.append(torch.nn.Flatten())
        c = 128 * 128 * 3
        for s in layer_size:
            layers.append(torch.nn.Linear(c, s))
            layers.append(torch.nn.ReLU())
            c = s
        layers.append(torch.nn.Linear(c, 102))
        self.model = torch.nn.Sequential(*layers)

    def forward(self, x) -> Any:
        return self.model(x)


# **Step 2: Visualizing Images**
def visualize_image(img: torch.Tensor) -> Image.Image:
    return Image.fromarray(
        (img.permute(1, 2, 0) * 255).to(torch.uint8).numpy()
    )

# Visualize the first 40 images
f, ax = plt.subplots(4, 10, figsize=(12, 6))
for i, (im, l) in enumerate(list(train_dataset)[:40]):
    ax[i // 10, i % 10].imshow(visualize_image(im))
    ax[i // 10, i % 10].set_title(l)
    ax[i // 10, i % 10].axis("off")
plt.tight_layout()
plt.show()

# **Step 3: Prepare Classes**
class_0 = list(train_dataset)[:10]
class_1 = list(train_dataset)[10:20]
class_01 = class_0 + class_1  # Combined class

# **Step 4: KNN Classifier**
def knn_classifier(x, k=3):
    dist = [((x - im).pow(2).sum(), l) for im, l in class_01]
    k_closest = [l for _, l in sorted(dist)[:k]]
    return sorted(k_closest)[k // 2]  # Return the median of the k closest labels

# **Step 5: Accuracy Calculation for Classifier**
accuracy = sum(knn_classifier(x) == l for x, l in list(test_dataset)[:20]) / 20
print(f"KNN Classifier Accuracy: {accuracy:.2f}")

# **Step 6: KNN Regression**
def knn_regression(x, k=3):
    dist = [((x - im).pow(2).sum(), l) for im, l in class_01]
    k_closest = [l for _, l in sorted(dist)[:k]]
    return torch.mean(torch.tensor(k_closest).float())

# **Step 7: Example for KNN Regression**
predicted_value = knn_regression(test_dataset[3][0])
print(f"KNN Regression Predicted Value: {predicted_value.item()}")
