import torch
import torchvision
from torchvision.transforms import Compose, Resize, ToTensor
from PIL import Image
import matplotlib.pyplot as plt

# **Step 1: Dataset Preparation**
# Define the image size and transformations
size = (128, 128)
transform = Compose([
    Resize(size),
    ToTensor()
])

//
Thanks for your time yesterday. I wanted to summarize the key point of why I reached out.
Over the past few years, whenever we discussed talent strategy, you always took the names of A and B in the same breath. My understanding was that you were advocating for both of us—it just hadn’t been approved due to organizational constraints. However, given how things unfolded this year, there seems to be a shift from our past discussions, which is why I had these questions.
I know you were short on time yesterday, so I would like to continue this conversation when you're back. In the meantime, I will work with Kristy on the proposed operating model for arch.
Safe travels!


from torchvision import datasets
from torchvision.transforms import ToTensor

train_data = datasets.FashionMNIST(root="data", train=True, download=True, transform=ToTensor())
test_data = datasets.FashionMNIST(root="data", train=False, download=True, transform=ToTensor())

# Extract train and test labels
train_data_labels = train_data.targets
test_data_labels = test_data.targets


import matplotlib.pyplot as plt
figure = plt.figure(figsize=(8, 8))
figure.add_subplot(1,6,1)

i=1000
img, label = train_data[i]
# print("img squeeze ", img.squeeze().shape)
# print("img without squeeze ", img.shape)

plt.title(label)
# plt.axis("off")
plt.imshow(img.squeeze(), cmap="gray")

# figure.add_subplot(1,6,6)
# img, label = train_data[200]

# plt.title(label)
# plt.imshow(img.squeeze(), cmap="gray")


# plt.show()


# Model definition #

model = torch.nn.Linear(28*28,10)
# model.parameters() #returns the weights and bias
loss = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), 0.1)

# Training Step #

# print("Weights = ", model.weight.shape)
# print("Bias = ", model.bias)

wt_mean_square = model.weight.pow(2).mean()
print("Weights MSE before training", wt_mean_square.item())

bias_mean_square = model.bias.pow(2).mean()
print("Bias MSE before training", bias_mean_square.item())

metrics = {"train_acc": [], "val_acc": []}

for i in range(60000):
    pred = model(train_data[i][0].squeeze().flatten())
    # print("Pred = ", pred)
    # print("Label = ", train_data[i][1])
    # print("Step ", i)

    optimizer.zero_grad()
    loss_val = loss(pred,torch.tensor(train_data[i][1]))
    loss_val.backward()
    # print("Weights Grad = ", model.weight.grad.pow(2).mean().item())
    optimizer.step()
    train_acc = (torch.argmax(pred) == train_data[i][1]).sum()
    print("Pred = ", torch.argmax(pred), " Label = ", train_data[i][1], " Match = ", torch.argmax(pred) == train_data[i][1])
    metrics["train_acc"].append(train_acc.item())


# print("Weights = ", model.weight)
# print("Bias = ", model.bias)
print("metrics[train_acc] = ", metrics["train_acc"])
print("Accuracy % = ", sum(metrics["train_acc"]) / len(metrics["train_acc"]) * 100)


wt_mean_square = model.weight.pow(2).mean()
print("Weights MSE after training", wt_mean_square.item())

bias_mean_square = model.bias.pow(2).mean()
print("Bias MSE after training", bias_mean_square.item())



# Validation #
metrics = {"val_acc": [], "preds": []}

labels_map = {
    0: "T-Shirt",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle Boot",
}

for i in range(10000):
    pred = model(train_data[i][0].squeeze().flatten())
    # print(torch.argmax(pred)==train_data[i][1])
    metrics["preds"].append(labels_map[torch.argmax(pred).item()])
    acc = (torch.argmax(pred)==train_data[i][1]).sum()
    metrics["val_acc"].append(acc.item())

print("Accuracy % =", sum(metrics["val_acc"])/ len(metrics["val_acc"]) * 100)
print("Pred Accuracy =",metrics["val_acc"] )
print("Predictions =",metrics["preds"] )

import matplotlib.pyplot as plt
figure = plt.figure(figsize=(8, 8))
figure.add_subplot(1,6,1)

i=2
img, label = test_data[i]
# print("img squeeze ", img.squeeze().shape)
# print("img without squeeze ", img.shape)

plt.title(label)
# plt.axis("off")
plt.imshow(img.squeeze(), cmap="gray")

//
# Load the Flowers102 dataset
train_dataset = torchvision.datasets.Flowers102(
    "./flowers", "train", transform=transform, download=True
)
test_dataset = torchvision.datasets.Flowers102(
    "./flowers", "train", transform=transform, download=True
)

import torch
import torch.nn as nn

class MyModel(torch.nn.Module):
    def __init__(self, layer_size=[512, 512, 512]) -> None:
        super().__init__()
        layers = []
        layers.append(torch.nn.Flatten())
        c = 128 * 128 * 3
        for s in layer_size:
            layers.append(torch.nn.Linear(c, s))
            layers.append(torch.nn.ReLU())
            c = s
        layers.append(torch.nn.Linear(c, 102))
        self.model = torch.nn.Sequential(*layers)

    def forward(self, x) -> Any:
        return self.model(x)


# **Step 2: Visualizing Images**
def visualize_image(img: torch.Tensor) -> Image.Image:
    return Image.fromarray(
        (img.permute(1, 2, 0) * 255).to(torch.uint8).numpy()
    )

# Visualize the first 40 images
f, ax = plt.subplots(4, 10, figsize=(12, 6))
for i, (im, l) in enumerate(list(train_dataset)[:40]):
    ax[i // 10, i % 10].imshow(visualize_image(im))
    ax[i // 10, i % 10].set_title(l)
    ax[i // 10, i % 10].axis("off")
plt.tight_layout()
plt.show()

# **Step 3: Prepare Classes**
class_0 = list(train_dataset)[:10]
class_1 = list(train_dataset)[10:20]
class_01 = class_0 + class_1  # Combined class

# **Step 4: KNN Classifier**
def knn_classifier(x, k=3):
    dist = [((x - im).pow(2).sum(), l) for im, l in class_01]
    k_closest = [l for _, l in sorted(dist)[:k]]
    return sorted(k_closest)[k // 2]  # Return the median of the k closest labels

# **Step 5: Accuracy Calculation for Classifier**
accuracy = sum(knn_classifier(x) == l for x, l in list(test_dataset)[:20]) / 20
print(f"KNN Classifier Accuracy: {accuracy:.2f}")

# **Step 6: KNN Regression**
def knn_regression(x, k=3):
    dist = [((x - im).pow(2).sum(), l) for im, l in class_01]
    k_closest = [l for _, l in sorted(dist)[:k]]
    return torch.mean(torch.tensor(k_closest).float())

# **Step 7: Example for KNN Regression**
predicted_value = knn_regression(test_dataset[3][0])
print(f"KNN Regression Predicted Value: {predicted_value.item()}")
